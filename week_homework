# coding:utf-8
import urllib
import os
import random
import string
'''
1.定义一个func(url, folder_path)
获取url地址的内容保存到folder_path的文件目录下，并随机生成一个文件名
2.定义一个func(folder_path),合并该目录下的所有文件，生成一个all.txt
3.定义一个func(url),分析该url内容里有多少个链接
4.定义一个func(url),获取？后的参数，并返回成一个dict:
assert('http://url/api?param=2&param2=4') == {'param':'2','param2':'4'}
5.定义一个func(folder).删除该folder下的所有文件
'''
def get_web(url, folder_path):
    assert os.path.isdir(folder_path),"Error, don't find the path"
    try:
        webopen = urllib.urlopen(url)   #检测是否能打开
    except:
        print "Error, can't open url"
    else:
        webget = webopen.read()
        #取小写字母中随机数（4-10）的字母
        filename = ''.join(random.sample(string.lowercase,random.randint(4,11)))
        os.chdir(folder_path)
        aFile = open(filename, 'w')
        aFile.write(webget)
        aFile.close()
        webopen.close()
        return "ok"

print get_web(r'http://cn.bing.com/',r"E:\BaiduYunDownload")
import glob
def path_all_file(folder_path):
    assert os.path.isdir(folder_path)
    with open("all.txt","ab+") as allfile  #需要打开微二进制文件   
    for File in glob.iglob(folder_path+"\*"):
        openfile = File.open()
        readFile = openfile.read()
        allfile.write(readFile)
        File.close()

